{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trustpilot_analyser.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfwCyZEgCGKD"
      },
      "source": [
        "# Анализ отзывов клиентов\n",
        "На примере сайта [trustpilot.com](https://www.trustpilot.com/review/flixbus.com) и компании flixbus\n",
        "\n",
        "Идея работника фирмы flixbus **Shukhrat Khodjaev**\n",
        "https://clck.ru/V8LDY\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhMmxxjy24qr"
      },
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from time import sleep\n",
        "import datetime\n",
        "import json\n",
        "\n",
        "def clean_string(column):\n",
        "    return column.apply(lambda x: x.replace(\"\\n\",'',2)).apply(lambda x: x.replace('  ',''))\n",
        "    \n",
        "# процедура парсит отзывы с сайта https://www.trustpilot.com\n",
        "# работала 28 мая 2021 года\n",
        "\n",
        "url_main='https://www.trustpilot.com'\n",
        "\n",
        "def parse_reviews(company_url, page_max=2, sleep_time = 0.5):\n",
        "# адрес основного сайта и начальный запрос\n",
        "  url0=url_main; path='/review/' + company_url\n",
        "\n",
        "# списки вытаскиваемых данных\n",
        "  names = []     # имя пользователя\n",
        "  ratings = []   # рейтинг от пользователя (от 1 до 5)\n",
        "  headers = []   # заголовок отзыва\n",
        "  reviews = []   # текст отзыва\n",
        "  dates = []     # дата отзыва\n",
        "  countries = [] # страна пользователя\n",
        "\n",
        "  page=0; rec=0;\n",
        "  while(path):\n",
        "    page += 1\n",
        "    if (page_max > 0) and (page > page_max): # отрабатываем нужное количество страниц, если задано\n",
        "      break\n",
        "    url = str(url0) + str(path)              # формируем полный адрес\n",
        "    http = requests.get(f'{url}')            # вытаскиваем страницу\n",
        "\n",
        "    bsoup = BeautifulSoup(http.text, 'html.parser') # варим суп (раскладываем на элементы)\n",
        "\n",
        "    # вытаскиваем ссылку на следующую страницу - переменная path\n",
        "    href = bsoup.find('a', href=True, rel=\"next\")\n",
        "    path = href['href'] if (href) else ''\n",
        "\n",
        "    # вытаскиваем данные по переменным в соотвествующие контейнеры\n",
        "    # размерности всех контейнеров должны быть одинаковыми и равны количеству отзывов на одной странице\n",
        "    country_container = bsoup.find_all('div', class_ = 'consumer-information__location')\n",
        "    nrec=len(country_container)\n",
        "\n",
        "    print(\"Парсим страницу\", page, \", записи\",rec+1,\"-\",rec+nrec,\"( адрес=\",url,\")\")\n",
        "    rec += nrec;\n",
        "\n",
        "    review_container = bsoup.find_all('div', class_ = 'review-content__body')\n",
        "    nrec1=len(review_container)\n",
        "    if (nrec1 != nrec): \n",
        "      print(\"ОШИБКА: число отзывов=\",nrec1,\"!=\",nrec,\"записей по стране!\")\n",
        "    rating_container = bsoup.find_all('div',class_ = \"star-rating star-rating--medium\")\n",
        "    nrec1=len(rating_container)\n",
        "    if (nrec1 != nrec): \n",
        "      print(\"ОШИБКА: число рейтингов=\",nrec1,\"!=\",nrec,\"записей по стране!\")\n",
        "    date_container = bsoup.find_all('div',class_ = \"review-content-header__dates\")\n",
        "    nrec1=len(date_container)\n",
        "    if (nrec1 != nrec): \n",
        "      print(\"ОШИБКА: число дат=\",nrec1,\"!=\",nrec,\"записей по стране!\")\n",
        "    name_container = bsoup.find_all('div',class_ = \"consumer-information__name\")\n",
        "    nrec1=len(name_container)\n",
        "    if (nrec1 != nrec): \n",
        "      print(\"ОШИБКА: число пользователей=\",nrec1,\"!=\",nrec,\"записей по стране!\")\n",
        "\n",
        "    # извлечение и запись переменных одного отзыва в общие списки\n",
        "    for x in range(nrec):\n",
        "      countries.append(country_container[x].text)\n",
        "      names.append(name_container[x].text)\n",
        "      headers.append(review_container[x].h2.a.text)\n",
        "      try:\n",
        "        reviews.append(review_container[x].p.text)\n",
        "      except AttributeError:\n",
        "        reviews.append(\"\")\n",
        "      dc = json.loads(date_container[x].script.text)\n",
        "      dates.append(datetime.datetime.strptime(dc[\"publishedDate\"][0:10],'%Y-%m-%d').date())\n",
        "      ratings.append(rating_container[x].img['alt'].split(' ')[0])\n",
        "\n",
        "  # формирование dataframe из собранных списков данных\n",
        "  rev_df = pd.DataFrame(list(zip(names, headers, reviews, ratings, dates, countries)),\n",
        "                  columns = ['Name','Header','Review','Rating', 'Date', 'Country'])\n",
        "    \n",
        "  # очистка от мусорных знаков и приведение к нужному типу переменных\n",
        "  rev_df.Name = clean_string(rev_df.Name)\n",
        "  rev_df.Header = clean_string(rev_df.Header)\n",
        "  rev_df.Review = clean_string(rev_df.Review)\n",
        "  rev_df.Rating = rev_df.Rating.astype('int')\n",
        "  rev_df.Date = pd.to_datetime(rev_df.Date)\n",
        "  rev_df.Country = clean_string(rev_df.Country)\n",
        "    \n",
        "  return rev_df # конец parse_reviews\n",
        "    \n",
        "print(\"Парсер parse_reviews для сайта\",url_main,\"загружен!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHuWbO2t8Ezz"
      },
      "source": [
        "df = parse_reviews(\"www.flixbus.com\",5)\n",
        "# df = parse_reviews(\"www.nationalexpress.com\",20)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXSHLX_ODbmO"
      },
      "source": [
        "## Сохранение данных \n",
        "\n",
        "Для последующей обработки, чтобы не мучить сайт, данные можно сохранить"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z62qntNPBD5l"
      },
      "source": [
        "df.to_csv(\"trustpilot_flixbus_reviews.csv\")"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m60VbBQJDlj0"
      },
      "source": [
        "## Гистограмма рейтинга\n",
        "Видно, что больше всего отзывов оставляют самые обиженные и самые довольные клиенты."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58LiWgcthBuT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "rt = df[\"Rating\"]\n",
        "rt.plot(kind=\"hist\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3of8o1TI9-1"
      },
      "source": [
        "## Отзывы по странам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH7byCsdDY8A"
      },
      "source": [
        "import seaborn as sns\n",
        "df1 = df.groupby(\"Country\").count().reset_index()\n",
        "df1.head()\n",
        "top_20 = df1.sort_values(by=['Review'], ascending=False).head(20)\n",
        "plt.figure(figsize=(12,10))\n",
        "plot = sns.barplot(top_20['Review'], top_20['Country'])\n",
        "for i,(value,name) in enumerate(zip(top_20['Review'],top_20['Country'])):\n",
        "  plot.text(value,i-0.05,f'{value:,.0f}',size=10)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOloes3WQJ2x"
      },
      "source": [
        "## Средний отзыв по странам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rQqRKNRJTM2"
      },
      "source": [
        "df2a = df.groupby(\"Country\").agg({\n",
        "    'Review' : lambda x: x.count(), \n",
        "    'Rating' : lambda x: x.mean(),\n",
        "    'Country': lambda x: x.max()})\n",
        "#df2a.rename(columns={'Review': 'NRev',      # число отзывов \n",
        "#                         'Rating': 'AveRT' # средний рейтинг\n",
        "#                    }, inplace=True)\n",
        "df2a.head()\n",
        "\n",
        "df2 = df2a[df2a[\"Review\"]>20] # смотрим только страны с заметным числом отзывов\n",
        "\n",
        "df2.head()\n",
        "\n",
        "rt = df2.sort_values(by=['Rating'], ascending=False)\n",
        "plt.figure(figsize=(12,10))\n",
        "plot = sns.barplot(rt['Rating'],rt['Country'])\n",
        "for i,(value,name) in enumerate(zip(rt['Rating'],rt['Country'])):\n",
        "  plot.text(value,i-0.05,f'{value:,.2f}',size=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38wzSM9gQPUy"
      },
      "source": [
        "df['my'] = df['Date'].dt.to_period('M') # добавление месячного интервала\n",
        "df.head()\n",
        "\n",
        "df3a = df.groupby(\"my\").agg({\n",
        "    'Review' : lambda x: x.count()/100, \n",
        "    'Rating' : lambda x: x.mean(),\n",
        "    'my': lambda x: x.max()})\n",
        "\n",
        "df3a.head()\n",
        "\n",
        "plt.figure(figsize=(12,50))\n",
        "df3a.plot(x=\"my\", y=[\"Review\", \"Rating\"])\n",
        "plt.legend([\"Средний рейтинг\", \"Число отзывов/100\"]);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}